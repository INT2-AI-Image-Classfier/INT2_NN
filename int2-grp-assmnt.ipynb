{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Very Helpful link\n",
            "# https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Makes File Handling Easier\n",
            "import os\n",
            "\n",
            "# PyTorch model and training necessities\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "import torch.optim as optim\n",
            "\n",
            "# from torch.utils.data import DataLoader\n",
            "\n",
            "# Image datasets and image manipulation\n",
            "import torchvision\n",
            "from torch.utils.data import Dataset\n",
            "from torchvision import datasets\n",
            "from torchvision.io import read_image\n",
            "import torchvision.transforms as transforms\n",
            "from PIL import Image\n",
            "import pandas as pd\n",
            "\n",
            "# Image display\n",
            "import matplotlib.pyplot as plt\n",
            "import numpy as np\n",
            "\n",
            "# PyTorch TensorBoard support\n",
            "from torch.utils.tensorboard.writer import SummaryWriter\n",
            "\n",
            "# ? Not sure what these are for\n",
            "import scipy.io as scio\n",
            "import shutil"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create train, valid and test directories to sort dataset into.\n",
            "def makePartitionDirs():\n",
            "    for i in range(1, 103):\n",
            "        os.makedirs(\"data/102flowers/train/\" + str(i), exist_ok=True)\n",
            "        os.makedirs(\"data/102flowers/test/\" + str(i), exist_ok=True)\n",
            "        os.makedirs(\"data/102flowers/valid/\" + str(i), exist_ok=True)\n",
            "\n",
            "\n",
            "# Distribute dataset into train, valid and test directories according to setid.mat specifications.\n",
            "def partitionData(imageLabels, setid, sortedPath, dataPath):\n",
            "    for i in range(len(imageLabels[\"labels\"][0])):\n",
            "        filename = \"image_\" + str(i + 1).zfill(5) + \".jpg\"\n",
            "        if i + 1 in setid[\"trnid\"][0]:\n",
            "            targetFolder = os.path.join(\n",
            "                sortedPath, \"train\", str(imageLabels[\"labels\"][0][i])\n",
            "            )\n",
            "        elif i + 1 in setid[\"valid\"][0]:\n",
            "            targetFolder = os.path.join(\n",
            "                sortedPath, \"valid\", str(imageLabels[\"labels\"][0][i])\n",
            "            )\n",
            "        else:\n",
            "            targetFolder = os.path.join(\n",
            "                sortedPath, \"test\", str(imageLabels[\"labels\"][0][i])\n",
            "            )\n",
            "        shutil.copy(\n",
            "            os.path.join(dataPath, filename), os.path.join(targetFolder, filename)\n",
            "        )"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "trainTransforms = transforms.Compose(\n",
            "    [\n",
            "        transforms.Resize(160),\n",
            "        transforms.RandomRotation(90),\n",
            "        transforms.CenterCrop(128),\n",
            "        transforms.RandomHorizontalFlip(),\n",
            "        transforms.RandomVerticalFlip(),\n",
            "        transforms.ToTensor(),\n",
            "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
            "    ]\n",
            ")\n",
            "testTransforms = validTransforms = transforms.Compose(\n",
            "    [\n",
            "        transforms.Resize(160),\n",
            "        transforms.ToTensor(),\n",
            "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
            "    ]\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "dataPath = \"data/102flowers/jpg\"\n",
            "sortedPath = \"data/102flowers\"\n",
            "setid = scio.loadmat(f\"data/setid.mat\")\n",
            "imageLabels: dict = scio.loadmat(f\"data/imagelabels.mat\")\n",
            "# Call these if you don't have the directories set up as needed.\n",
            "makePartitionDirs()\n",
            "partitionData(imageLabels, setid, sortedPath, dataPath)\n",
            "trainingData = datasets.ImageFolder(\n",
            "    root=\"data/102flowers/train\", transform=trainTransforms\n",
            ")\n",
            "validationData = datasets.ImageFolder(\n",
            "    root=\"data/102flowers/valid\", transform=validTransforms\n",
            ")\n",
            "testingData = datasets.ImageFolder(\n",
            "    root=\"data/102flowers/test\", transform=testTransforms\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Data loaders for use as input.\n",
            "in_batch_size = 16\n",
            "trainDataLoader = torch.utils.data.DataLoader(\n",
            "    trainingData, batch_size=in_batch_size, shuffle=True\n",
            ")\n",
            "validDataLoader = torch.utils.data.DataLoader(\n",
            "    validationData, batch_size=in_batch_size, shuffle=False\n",
            ")\n",
            "testDataLoader = torch.utils.data.DataLoader(\n",
            "    testingData, batch_size=in_batch_size, shuffle=False\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def showImage(image):\n",
            "    npImage = image.numpy()\n",
            "    plt.imshow(np.transpose(npImage, (1, 2, 0)))\n",
            "    plt.show()\n",
            "\n",
            "\n",
            "torch.manual_seed(12345)\n",
            "dataIter = iter(trainDataLoader)\n",
            "images, labels = next(dataIter)\n",
            "print(len(images))\n",
            "print(labels)\n",
            "showImage(torchvision.utils.make_grid(images))\n",
            "print(\" \".join(f\"{labels[j]}\" for j in range(4)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "figure = plt.figure(figsize=(8, 8))\n",
            "cols, rows = 3, 3\n",
            "for i in range(1, cols * rows + 1):\n",
            "    sample_idx = torch.randint(len(trainingData), size=(1,)).item()\n",
            "    img, label = trainingData[int(sample_idx)]\n",
            "    figure.add_subplot(rows, cols, i)\n",
            "    plt.title(label)\n",
            "    plt.axis(\"off\")\n",
            "    print(img.squeeze().shape)\n",
            "    processed_image = np.rollaxis(img.squeeze().numpy(), 0, 3)\n",
            "    plt.imshow(processed_image)\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # The CNN Network\n",
            "# class Net(nn.Module):\n",
            "#     def __init__(self, img_size=256):\n",
            "#         super(Net, self).__init__()\n",
            "#         self.img_size = img_size\n",
            "#         # 3 input image channel, 6 output channels, 5x5 square convolution\n",
            "#         # kernel\n",
            "#         # self.conv1 = nn.Conv2d(3, 6, img_size)\n",
            "#         # self.conv2 = nn.Conv2d(6, 16, img_size)\n",
            "#         # # an affine operation: y = Wx + b\n",
            "#         # self.fc1 = nn.Linear(16 * img_size**2, 120)  # 5*5 from image dimension\n",
            "#         # self.fc2 = nn.Linear(120, 84)\n",
            "#         # self.fc3 = nn.Linear(84, 10)\n",
            "\n",
            "#         conv1_1 =   nn.Conv2d()          #  64 3x3x3 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu1_1 =   nn.ReLU()            #       ReLU\n",
            "#         conv1_2 =   nn.Conv2d()          #  64 3x3x64 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu1_2 =   nn.ReLU()            #       ReLU\n",
            "#         pool1 =     nn.MaxPool2d()        #    2x2 max pooling with stride [2  2] and padding [0  0  0  0]\n",
            "#         conv2_1 =   nn.Conv2d()          #  128 3x3x64 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu2_1 =   nn.ReLU()            #       ReLU\n",
            "#         conv2_2 =   nn.Conv2d()          #  128 3x3x128 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu2_2 =  nn.ReLU()             #      ReLU\n",
            "#         pool2 =    nn.MaxPool2d()         #   2x2 max pooling with stride [2  2] and padding [0  0  0  0]\n",
            "#         conv3_1 =  nn.Conv2d()           # 256 3x3x128 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu3_1 =  nn.ReLU()             #      ReLU\n",
            "#         conv3_2 =  nn.Conv2d()           # 256 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu3_2 =  nn.ReLU()             #      ReLU\n",
            "#         conv3_3 =  nn.Conv2d()           # 256 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu3_3 =  nn.ReLU()             #      ReLU\n",
            "#         conv3_4 =  nn.Conv2d()           # 256 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu3_4 =  nn.ReLU()             #      ReLU\n",
            "#         pool3 =    nn.MaxPool2d()         #   2x2 max pooling with stride [2  2] and padding [0  0  0  0]\n",
            "#         conv4_1 =  nn.Conv2d()           # 512 3x3x256 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu4_1 =  nn.ReLU()             #      ReLU\n",
            "#         conv4_2 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu4_2 =  nn.ReLU()             #      ReLU\n",
            "#         conv4_3 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu4_3 =  nn.ReLU()             #      ReLU\n",
            "#         conv4_4 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu4_4 =  nn.ReLU()             #      ReLU\n",
            "#         pool4 =    nn.MaxPool2d()         #   2x2 max pooling with stride [2  2] and padding [0  0  0  0]\n",
            "#         conv5_1 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu5_1 =  nn.ReLU()             #      ReLU\n",
            "#         conv5_2 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu5_2 =  nn.ReLU()             #      ReLU\n",
            "#         conv5_3 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu5_3 =  nn.ReLU()             #      ReLU\n",
            "#         conv5_4 =  nn.Conv2d()           # 512 3x3x512 convolutions with stride [1  1] and padding [1  1  1  1]\n",
            "#         relu5_4 =  nn.ReLU()             #      ReLU\n",
            "#         pool5 =    nn.MaxPool2d()         #   2x2 max pooling with stride [2  2] and padding [0  0  0  0]\n",
            "#         fc6 =      nn.Linear()     #   4096 fully connected layer\n",
            "#         relu6 =    nn.ReLU()             #      ReLU\n",
            "#         drop6 =    nn.Dropout2d()             #   50% dropout\n",
            "#         fc7 =      nn.Linear()     #   4096 fully connected layer\n",
            "#         relu7 =    nn.ReLU()             #      ReLU\n",
            "#         drop7 =    nn.Dropout2d()             #   50% dropout\n",
            "#         fc8 =      nn.Linear()     #   1000 fully connected layer\n",
            "#         prob =     nn.Softmax2d()              #   softmax\n",
            "#         # output =   # Classification Output #   crossentropyex with 'tench' and 999 other classes\n",
            "\n",
            "#     def forward(self, x):\n",
            "#         # # Max pooling over a (2, 2) window\n",
            "#         # x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
            "#         # If the size is a square, you can specify with a single number\n",
            "#         # x = F.max_pool2d(F.relu(self.conv2(x)), self.img_size)\n",
            "#         # x = torch.flatten(x, 1)  # flatten all dimensions except the batch dimension\n",
            "#         # x = F.relu(self.fc1(x))\n",
            "#         # x = F.relu(self.fc2(x))\n",
            "#         # x = self.fc3(x)\n",
            "#         # return x\n",
            "#         x =\n",
            "#         return x\n",
            "\n",
            "\n",
            "# net = Net()\n",
            "# net"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# The CNN Network\n",
            "# Define a convolution neural network\n",
            "class Network(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(Network, self).__init__()\n",
            "\n",
            "        self.conv1 = nn.Conv2d(\n",
            "            in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1\n",
            "        )\n",
            "        self.bn1 = nn.BatchNorm2d(12)\n",
            "        self.conv2 = nn.Conv2d(\n",
            "            in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1\n",
            "        )\n",
            "        self.bn2 = nn.BatchNorm2d(12)\n",
            "        self.pool = nn.MaxPool2d(2, 2)\n",
            "        self.conv4 = nn.Conv2d(\n",
            "            in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1\n",
            "        )\n",
            "        self.bn4 = nn.BatchNorm2d(24)\n",
            "        self.conv5 = nn.Conv2d(\n",
            "            in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1\n",
            "        )\n",
            "        self.bn5 = nn.BatchNorm2d(24)\n",
            "        self.fc1 = nn.Linear(24 * 10 * 10, 10)\n",
            "\n",
            "    def forward(self, input):\n",
            "        output = F.relu(self.bn1(self.conv1(input)))\n",
            "        output = F.relu(self.bn2(self.conv2(output)))\n",
            "        output = self.pool(output)\n",
            "        output = F.relu(self.bn4(self.conv4(output)))\n",
            "        output = F.relu(self.bn5(self.conv5(output)))\n",
            "        output = output.view(-1, 24 * 10 * 10)\n",
            "        output = self.fc1(output)\n",
            "\n",
            "        return output\n",
            "\n",
            "\n",
            "# Instantiate a neural network model\n",
            "model = Network()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# See the learnable parameters of our model\n",
            "params = list(net.parameters())\n",
            "print(len(params))\n",
            "print(params[0].size())  # conv1's .weight"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Generate a random 32x32 image, what the models wants\n",
            "input = torch.randn(1, 1, 32, 32)\n",
            "out = net(input)\n",
            "print(out)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Zero the gradient buffers of all parameters and backprops with random gradients\n",
            "net.zero_grad()\n",
            "out.backward(torch.randn(1, 10))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Does this device have a GPU?\n",
            "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
            "\n",
            "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
            "print(device)\n",
            "\n",
            "# Use the GPU if its there, otherwise use the CPU\n",
            "net.to(device)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Loss function\n",
            "criterion = nn.CrossEntropyLoss()\n",
            "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Train the Network\n",
            "for epoch in range(2):  # loop over the dataset multiple times\n",
            "    running_loss = 0.0\n",
            "    for i, data in enumerate(trainDataLoader, 0):\n",
            "        # Get the inputs; data is a list of [inputs, labels] # inputs, labels = data\n",
            "        # And send all the inputs and targets at every step to the chosen device\n",
            "        inputs, labels = data[0].to(device), data[1].to(device)\n",
            "\n",
            "        # zero the parameter gradients\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        # forward + backward + optimize\n",
            "        outputs = net(inputs)  # This is the Forward Pass\n",
            "        loss = criterion(outputs, labels)\n",
            "        loss.backward()  # This is the Backward Pass\n",
            "        optimizer.step()  # This is the optimizer\n",
            "\n",
            "        # print statistics\n",
            "        running_loss += loss.item()\n",
            "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
            "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}\")\n",
            "            running_loss = 0.0\n",
            "\n",
            "print(\"Finished Training\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Save the trained network\n",
            "PATH = \"./flowers102.pth\"\n",
            "torch.save(net.state_dict(), PATH)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Test the network\n",
            "dataiter = iter(testDataLoader)\n",
            "images, labels = next(dataiter)\n",
            "\n",
            "# print images\n",
            "plt.imshow(torchvision.utils.make_grid(images))\n",
            "print(\"GroundTruth: \", \" \".join(f\"{labels[j]:5s}\" for j in range(4)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Load back the saved network\n",
            "net = Net()\n",
            "net.load_state_dict(torch.load(PATH))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Get predictions\n",
            "outputs = net(images)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Lets get the images which the AI thinks is the strongest case of each class\n",
            "_, predicted = torch.max(outputs, 1)\n",
            "\n",
            "print(\"Predicted: \", \" \".join(f\"{predicted[j]:5s}\" for j in range(4)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Gauge the performance of the network\n",
            "correct = 0\n",
            "total = 0\n",
            "# since we're not training, we don't need to calculate the gradients for our outputs\n",
            "with torch.no_grad():\n",
            "    for data in testDataLoader:\n",
            "        images, labels = data\n",
            "        # calculate outputs by running images through the network\n",
            "        outputs = net(images)\n",
            "        # the class with the highest energy is what we choose as prediction\n",
            "        _, predicted = torch.max(outputs.data, 1)\n",
            "        total += labels.size(0)\n",
            "        correct += (predicted == labels).sum().item()\n",
            "\n",
            "print(f\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Get the predictions accuracy of each class\n",
            "\n",
            "# prepare to count predictions for each class\n",
            "correct_pred = {classname: 0 for classname in labels}\n",
            "total_pred = {classname: 0 for classname in labels}\n",
            "\n",
            "# again no gradients needed\n",
            "with torch.no_grad():\n",
            "    for data in testDataLoader:\n",
            "        images, labels = data\n",
            "        outputs = net(images)\n",
            "        _, predictions = torch.max(outputs, 1)\n",
            "        # collect the correct predictions for each class\n",
            "        for label, prediction in zip(labels, predictions):\n",
            "            if label == prediction:\n",
            "                correct_pred[label] += 1\n",
            "            total_pred[label] += 1\n",
            "\n",
            "\n",
            "# print accuracy for each class\n",
            "for classname, correct_count in correct_pred.items():\n",
            "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
            "    print(f\"Accuracy for class: {classname:5s} is {accuracy:.1f} %\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Cleanup\n",
            "del dataiter"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "base",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.9"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
